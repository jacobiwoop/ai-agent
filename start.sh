#!/bin/bash
set -e

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  COULEURS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
CYAN='\033[0;36m'
BOLD='\033[1m'
NC='\033[0m'

info()    { echo -e "${GREEN}[âœ”]${NC} $1"; }
warning() { echo -e "${YELLOW}[~]${NC} $1"; }
error()   { echo -e "${RED}[âœ˜]${NC} $1"; exit 1; }
ask()     { echo -e "${CYAN}[?]${NC} $1"; }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  1. SE PLACER DANS LE DOSSIER DU PROJET
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SCRIPT_DIR="$(cd "$(dirname "$0")" && pwd)"
cd "$SCRIPT_DIR"
ENV_FILE="ai-coding-agent/.env"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  2. SETUP WIZARD â€” crÃ©er le .env si absent
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if [ ! -f "$ENV_FILE" ]; then
    echo ""
    echo -e "${BOLD}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
    echo -e "${BOLD}â•‘       ðŸ›   Configuration initiale           â•‘${NC}"
    echo -e "${BOLD}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo ""
    warning "Fichier .env absent. Lancement de l'assistant de configuration..."
    echo ""

    # --- LLM Backend ---
    ask "URL du backend LLM (dÃ©faut: http://localhost:11434/v1 pour Ollama local) :"
    read -r INPUT_BASE_URL
    BASE_URL="${INPUT_BASE_URL:-http://localhost:11434/v1}"

    ask "ClÃ© API du backend LLM (dÃ©faut: ollama) :"
    read -r INPUT_API_KEY
    API_KEY="${INPUT_API_KEY:-ollama}"

    # --- Telegram ---
    echo ""
    ask "Token du bot Telegram (depuis @BotFather, laissez vide pour ignorer) :"
    read -r TELEGRAM_BOT_TOKEN

    if [ -n "$TELEGRAM_BOT_TOKEN" ]; then
        ask "Votre Chat ID Telegram personnel (depuis @userinfobot) :"
        read -r TELEGRAM_AUTHORIZED_CHAT_ID
    fi

    # --- Groq Whisper ---
    echo ""
    ask "ClÃ© API Groq pour la transcription vocale Whisper (console.groq.com, laissez vide pour ignorer) :"
    read -r GROQ_API_KEY

    # --- Ã‰criture du .env ---
    cat > "$ENV_FILE" <<EOF
# Agent Configuration
API_KEY=${API_KEY}
BASE_URL=${BASE_URL}

# Telegram Bot Integration
TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
TELEGRAM_AUTHORIZED_CHAT_ID=${TELEGRAM_AUTHORIZED_CHAT_ID}

# Groq Whisper - Transcription vocale
GROQ_API_KEY=${GROQ_API_KEY}
EOF

    echo ""
    info "Fichier .env crÃ©Ã© avec succÃ¨s â†’ $ENV_FILE"
    echo ""
else
    info "Fichier .env trouvÃ©."
fi

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  3. VÃ‰RIFIER / INSTALLER OLLAMA
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if ! command -v ollama &>/dev/null; then
    warning "Ollama non trouvÃ©. Installation en cours..."
    curl -fsSL https://ollama.ai/install.sh | sh
    info "Ollama installÃ©."
else
    info "Ollama dÃ©jÃ  installÃ©."
fi

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  4. VÃ‰RIFIER / DÃ‰MARRER LE SERVEUR OLLAMA
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if ! curl -s http://localhost:11434 &>/dev/null; then
    warning "Serveur Ollama inactif. DÃ©marrage en arriÃ¨re-plan..."
    ollama serve &>/dev/null &
    for i in $(seq 1 15); do
        if curl -s http://localhost:11434 &>/dev/null; then break; fi
        sleep 1
    done
    if ! curl -s http://localhost:11434 &>/dev/null; then
        error "Le serveur Ollama n'a pas pu dÃ©marrer."
    fi
    info "Serveur Ollama dÃ©marrÃ©."
else
    info "Serveur Ollama dÃ©jÃ  actif."
fi

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  5. CONNEXION OLLAMA (modÃ¨les Cloud)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if ! ollama list 2>/dev/null | grep -q ":cloud"; then
    warning "Connexion Ollama requise pour les modÃ¨les Cloud."
    echo ""
    ollama login
    info "Connexion Ollama rÃ©ussie."
else
    info "DÃ©jÃ  connectÃ© Ã  Ollama."
fi

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  6. VÃ‰RIFIER / INSTALLER LES MODÃˆLES
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODELS=(
    "gemma3:27b-cloud"
    "kimi-k2.5:cloud"
    "deepseek-v3.2:cloud"
    "glm-4.6:cloud"
    "qwen3-coder-next:cloud"
    "qwen3-coder:480b-cloud"
)

INSTALLED=$(ollama list 2>/dev/null | awk 'NR>1 {print $1}')

for MODEL in "${MODELS[@]}"; do
    if echo "$INSTALLED" | grep -q "^$MODEL$"; then
        info "ModÃ¨le dÃ©jÃ  prÃ©sent : $MODEL"
    else
        warning "Installation du modÃ¨le : $MODEL"
        ollama pull "$MODEL"
        info "ModÃ¨le installÃ© : $MODEL"
    fi
done

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  7. LANCER LE PROJET
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo ""
info "Lancement de l'agent AI..."
source .venv/bin/activate
python ai-coding-agent/main.py "$@"
